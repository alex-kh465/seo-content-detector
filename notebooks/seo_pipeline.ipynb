{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEO Content Quality & Duplicate Detector - Enhanced Analysis\n",
    "\n",
    "This notebook demonstrates advanced NLP analysis including sentiment analysis, named entity recognition, topic modeling, and comprehensive visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add streamlit_app/utils to path\n",
    "sys.path.insert(0, os.path.join('..', 'streamlit_app', 'utils'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Download NLTK data\n",
    "for resource in ['vader_lexicon', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words', 'punkt']:\n",
    "    try:\n",
    "        nltk.data.find(f'tokenizers/{resource}')\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download(resource, quiet=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "from parser import parse_dataset, extract_text_from_html\n",
    "from features import extract_features_from_dataset, extract_features\n",
    "from similarity import detect_duplicates, parse_embedding\n",
    "from scorer import train_quality_model, predict_quality\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data first\n",
    "df = pd.read_csv('../data/extracted_content.csv')\n",
    "df['body_text'] = df['body_text'].fillna('')\n",
    "df.to_csv('../data/extracted_content.csv', index=False)\n",
    "\n",
    "print(f\"Loaded {len(df)} pages\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract NLP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features_df, embeddings = extract_features_from_dataset(\n",
    "    '../data/extracted_content.csv',\n",
    "    '../data/features.csv'\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures extracted for {len(features_df)} pages\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced NLP Analysis\n",
    "\n",
    "### 4.1 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis using VADER\n",
    "print(\"Performing sentiment analysis...\")\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentiments = []\n",
    "for text in df['body_text'][:100]:  # Sample first 100 for speed\n",
    "    if text and len(text) > 10:\n",
    "        scores = sia.polarity_scores(text[:5000])  # Limit text length\n",
    "        sentiments.append(scores)\n",
    "    else:\n",
    "        sentiments.append({'neg': 0, 'neu': 0, 'pos': 0, 'compound': 0})\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiments)\n",
    "\n",
    "# Classify sentiment\n",
    "sentiment_df['sentiment'] = sentiment_df['compound'].apply(\n",
    "    lambda x: 'Positive' if x > 0.05 else ('Negative' if x < -0.05 else 'Neutral')\n",
    ")\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(sentiment_df['sentiment'].value_counts())\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Sentiment counts\n",
    "sentiment_counts = sentiment_df['sentiment'].value_counts()\n",
    "axes[0].bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'gray', 'red'])\n",
    "axes[0].set_title('Sentiment Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Compound score distribution\n",
    "axes[1].hist(sentiment_df['compound'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(0, color='red', linestyle='--', label='Neutral')\n",
    "axes[1].set_xlabel('Compound Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Compound Sentiment Score Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "# Positive/Negative/Neutral proportions\n",
    "sentiment_props = sentiment_df[['pos', 'neu', 'neg']].mean()\n",
    "axes[2].pie(sentiment_props, labels=['Positive', 'Neutral', 'Negative'], \n",
    "            autopct='%1.1f%%', colors=['green', 'gray', 'red'])\n",
    "axes[2].set_title('Average Sentiment Proportions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract named entities from sample texts\n",
    "print(\"Extracting named entities...\")\n",
    "\n",
    "def extract_entities(text, max_length=1000):\n",
    "    \"\"\"Extract named entities from text.\"\"\"\n",
    "    if not text or len(text) < 10:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Limit text length for performance\n",
    "        text_sample = text[:max_length]\n",
    "        tokens = word_tokenize(text_sample)\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        chunks = ne_chunk(pos_tags, binary=False)\n",
    "        \n",
    "        entities = []\n",
    "        for chunk in chunks:\n",
    "            if hasattr(chunk, 'label'):\n",
    "                entity = ' '.join(c[0] for c in chunk)\n",
    "                entities.append((entity, chunk.label()))\n",
    "        \n",
    "        return entities\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Extract entities from first 20 documents\n",
    "all_entities = []\n",
    "for text in df['body_text'][:20]:\n",
    "    entities = extract_entities(text)\n",
    "    all_entities.extend(entities)\n",
    "\n",
    "# Count entity types\n",
    "entity_types = Counter([ent[1] for ent in all_entities])\n",
    "entity_names = Counter([ent[0] for ent in all_entities])\n",
    "\n",
    "print(f\"\\nTotal entities found: {len(all_entities)}\")\n",
    "print(f\"\\nTop entity types:\")\n",
    "for ent_type, count in entity_types.most_common(5):\n",
    "    print(f\"  {ent_type}: {count}\")\n",
    "\n",
    "print(f\"\\nTop entities:\")\n",
    "for ent_name, count in entity_names.most_common(10):\n",
    "    print(f\"  {ent_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize entity types\n",
    "if len(entity_types) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Entity type distribution\n",
    "    entity_type_df = pd.DataFrame(entity_types.most_common(10), columns=['Type', 'Count'])\n",
    "    axes[0].barh(entity_type_df['Type'], entity_type_df['Count'])\n",
    "    axes[0].set_xlabel('Count')\n",
    "    axes[0].set_title('Top Named Entity Types')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    # Top entities\n",
    "    entity_name_df = pd.DataFrame(entity_names.most_common(15), columns=['Entity', 'Count'])\n",
    "    axes[1].barh(entity_name_df['Entity'], entity_name_df['Count'])\n",
    "    axes[1].set_xlabel('Count')\n",
    "    axes[1].set_title('Top Named Entities')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform topic modeling using LDA\n",
    "print(\"Performing topic modeling...\")\n",
    "\n",
    "# Prepare texts (sample first 100 for speed)\n",
    "texts_sample = [text for text in df['body_text'][:100] if text and len(text) > 50]\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    max_df=0.8,\n",
    "    min_df=2,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(texts_sample)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Fit LDA model\n",
    "n_topics = 5\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=20\n",
    ")\n",
    "\n",
    "lda.fit(doc_term_matrix)\n",
    "\n",
    "# Display topics\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        topics.append(top_words)\n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\", \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "topics = display_topics(lda, feature_names, n_top_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topic word weights\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for topic_idx in range(n_topics):\n",
    "    top_words_idx = lda.components_[topic_idx].argsort()[-10:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    weights = [lda.components_[topic_idx][i] for i in top_words_idx]\n",
    "    \n",
    "    axes[topic_idx].barh(top_words, weights)\n",
    "    axes[topic_idx].set_title(f'Topic {topic_idx + 1}')\n",
    "    axes[topic_idx].set_xlabel('Weight')\n",
    "    axes[topic_idx].invert_yaxis()\n",
    "\n",
    "# Hide extra subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Improved Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords using TF-IDF\n",
    "print(\"Extracting keywords with TF-IDF...\")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50,\n",
    "    ngram_range=(1, 2),  # Include bigrams\n",
    "    stop_words='english',\n",
    "    max_df=0.8,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(texts_sample)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Get average TF-IDF scores\n",
    "avg_tfidf = np.mean(tfidf_matrix.toarray(), axis=0)\n",
    "top_keywords_idx = avg_tfidf.argsort()[-20:][::-1]\n",
    "top_keywords = [(feature_names[i], avg_tfidf[i]) for i in top_keywords_idx]\n",
    "\n",
    "print(\"\\nTop 20 Keywords (by TF-IDF):\")\n",
    "for keyword, score in top_keywords:\n",
    "    print(f\"  {keyword}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top keywords\n",
    "keyword_df = pd.DataFrame(top_keywords, columns=['Keyword', 'TF-IDF Score'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(keyword_df['Keyword'], keyword_df['TF-IDF Score'])\n",
    "plt.xlabel('Average TF-IDF Score')\n",
    "plt.title('Top 20 Keywords by TF-IDF')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Visualizations\n",
    "\n",
    "### 5.1 Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds for different quality levels\n",
    "print(\"Generating word clouds...\")\n",
    "\n",
    "# Combine all text\n",
    "all_text = ' '.join(df['body_text'][:100].dropna())\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    background_color='white',\n",
    "    stopwords='english',\n",
    "    max_words=100,\n",
    "    colormap='viridis'\n",
    ").generate(all_text)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - All Content', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Similarity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and compute similarity matrix\n",
    "features_df = pd.read_csv('../data/features.csv')\n",
    "\n",
    "# Parse embeddings for sample (first 30 for visualization)\n",
    "sample_size = min(30, len(features_df))\n",
    "embeddings_sample = []\n",
    "\n",
    "for idx in range(sample_size):\n",
    "    emb = parse_embedding(features_df.iloc[idx]['embedding'])\n",
    "    if emb is not None:\n",
    "        embeddings_sample.append(emb)\n",
    "\n",
    "embeddings_sample = np.array(embeddings_sample)\n",
    "\n",
    "# Compute similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(embeddings_sample)\n",
    "\n",
    "# Visualize similarity heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    similarity_matrix,\n",
    "    cmap='YlOrRd',\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Cosine Similarity'}\n",
    ")\n",
    "plt.title(f'Content Similarity Heatmap (Sample of {sample_size} Pages)', fontsize=14, pad=20)\n",
    "plt.xlabel('Page Index')\n",
    "plt.ylabel('Page Index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage similarity: {similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)].mean():.4f}\")\n",
    "print(f\"Max similarity (excluding diagonal): {np.max(similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Feature Importance and Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model, X_test, y_test, y_pred, feature_names, metrics = train_quality_model(\n",
    "    '../data/features.csv',\n",
    "    '../streamlit_app/models/quality_model.pkl',\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model visualizations\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Feature importance\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "feature_importance = metrics['feature_importance']\n",
    "ax1.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "ax1.set_xlabel('Importance')\n",
    "ax1.set_title('Feature Importance')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Confusion matrix\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "cm = metrics['confusion_matrix']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Low', 'Medium', 'High'],\n",
    "            yticklabels=['Low', 'Medium', 'High'],\n",
    "            ax=ax2)\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "ax2.set_title('Confusion Matrix')\n",
    "\n",
    "# Model performance comparison\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "models = ['RandomForest', 'Baseline']\n",
    "accuracy_scores = [metrics['accuracy'], metrics['baseline_accuracy']]\n",
    "f1_scores = [metrics['f1_score'], metrics['baseline_f1']]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x - width/2, accuracy_scores, width, label='Accuracy', color='skyblue')\n",
    "ax3.bar(x + width/2, f1_scores, width, label='F1 Score', color='lightcoral')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('Model Performance Comparison')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(models)\n",
    "ax3.legend()\n",
    "ax3.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(accuracy_scores):\n",
    "    ax3.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "for i, v in enumerate(f1_scores):\n",
    "    ax3.text(i + width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Feature distributions by quality\n",
    "features_df = pd.read_csv('../data/features.csv')\n",
    "if 'predicted_quality' in features_df.columns:\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    for quality in ['Low', 'Medium', 'High']:\n",
    "        subset = features_df[features_df['predicted_quality'] == quality]\n",
    "        if len(subset) > 0:\n",
    "            ax4.scatter(subset['word_count'], subset['flesch_reading_ease'], \n",
    "                       alpha=0.6, label=quality, s=50)\n",
    "    ax4.set_xlabel('Word Count')\n",
    "    ax4.set_ylabel('Flesch Reading Ease')\n",
    "    ax4.set_title('Quality Distribution by Features')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Quality distribution\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    quality_counts = features_df['predicted_quality'].value_counts()\n",
    "    colors = {'High': 'green', 'Medium': 'orange', 'Low': 'red'}\n",
    "    bar_colors = [colors.get(q, 'gray') for q in quality_counts.index]\n",
    "    ax5.bar(quality_counts.index, quality_counts.values, color=bar_colors, alpha=0.7)\n",
    "    ax5.set_xlabel('Quality Level')\n",
    "    ax5.set_ylabel('Count')\n",
    "    ax5.set_title('Predicted Quality Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Distribution Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive distribution analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Word count distribution\n",
    "axes[0, 0].hist(features_df['word_count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(features_df['word_count'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 0].axvline(features_df['word_count'].median(), color='green', linestyle='--', label='Median')\n",
    "axes[0, 0].set_xlabel('Word Count')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Word Count Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Sentence count distribution\n",
    "axes[0, 1].hist(features_df['sentence_count'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 1].set_xlabel('Sentence Count')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Sentence Count Distribution')\n",
    "\n",
    "# Readability distribution\n",
    "axes[0, 2].hist(features_df['flesch_reading_ease'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 2].axvline(50, color='red', linestyle='--', alpha=0.5, label='Min Optimal')\n",
    "axes[0, 2].axvline(70, color='red', linestyle='--', alpha=0.5, label='Max Optimal')\n",
    "axes[0, 2].set_xlabel('Flesch Reading Ease')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].set_title('Readability Distribution')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# Box plots\n",
    "axes[1, 0].boxplot([features_df['word_count']])\n",
    "axes[1, 0].set_ylabel('Word Count')\n",
    "axes[1, 0].set_title('Word Count Box Plot')\n",
    "axes[1, 0].set_xticklabels([''])\n",
    "\n",
    "axes[1, 1].boxplot([features_df['sentence_count']])\n",
    "axes[1, 1].set_ylabel('Sentence Count')\n",
    "axes[1, 1].set_title('Sentence Count Box Plot')\n",
    "axes[1, 1].set_xticklabels([''])\n",
    "\n",
    "axes[1, 2].boxplot([features_df['flesch_reading_ease']])\n",
    "axes[1, 2].set_ylabel('Flesch Reading Ease')\n",
    "axes[1, 2].set_title('Readability Box Plot')\n",
    "axes[1, 2].set_xticklabels([''])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n=== Statistical Summary ===\")\n",
    "print(\"\\nWord Count:\")\n",
    "print(features_df['word_count'].describe())\n",
    "print(\"\\nSentence Count:\")\n",
    "print(features_df['sentence_count'].describe())\n",
    "print(\"\\nReadability:\")\n",
    "print(features_df['flesch_reading_ease'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Duplicate Detection Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect duplicates\n",
    "duplicates_df, similarity_matrix, summary_stats = detect_duplicates(\n",
    "    '../data/features.csv',\n",
    "    '../data/duplicates.csv',\n",
    "    threshold=0.80,\n",
    "    thin_threshold=500\n",
    ")\n",
    "\n",
    "print(f\"\\n{summary_stats['duplicate_pairs']} duplicate pairs found\")\n",
    "if len(duplicates_df) > 0:\n",
    "    duplicates_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize duplicate analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "if len(duplicates_df) > 0:\n",
    "    # Similarity score distribution\n",
    "    axes[0, 0].hist(duplicates_df['similarity'], bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(0.80, color='red', linestyle='--', label='Threshold')\n",
    "    axes[0, 0].set_xlabel('Similarity Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Duplicate Similarity Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Word count comparison for duplicates\n",
    "    axes[0, 1].scatter(duplicates_df['word_count_1'], duplicates_df['word_count_2'], alpha=0.6)\n",
    "    axes[0, 1].plot([0, duplicates_df[['word_count_1', 'word_count_2']].max().max()], \n",
    "                    [0, duplicates_df[['word_count_1', 'word_count_2']].max().max()], \n",
    "                    'r--', alpha=0.5)\n",
    "    axes[0, 1].set_xlabel('Word Count (URL 1)')\n",
    "    axes[0, 1].set_ylabel('Word Count (URL 2)')\n",
    "    axes[0, 1].set_title('Word Count Comparison for Duplicates')\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'No duplicates found', ha='center', va='center')\n",
    "    axes[0, 0].set_title('Duplicate Similarity Distribution')\n",
    "    axes[0, 1].text(0.5, 0.5, 'No duplicates found', ha='center', va='center')\n",
    "    axes[0, 1].set_title('Word Count Comparison')\n",
    "\n",
    "# Thin content analysis\n",
    "thin_content = features_df[features_df['word_count'] < 500]\n",
    "normal_content = features_df[features_df['word_count'] >= 500]\n",
    "\n",
    "axes[1, 0].bar(['Thin (<500)', 'Normal (>=500)'], \n",
    "               [len(thin_content), len(normal_content)],\n",
    "               color=['red', 'green'], alpha=0.7)\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Thin Content Detection')\n",
    "\n",
    "# Summary statistics\n",
    "summary_text = f\"\"\"\n",
    "Total Pages: {summary_stats['total_pages']}\n",
    "Duplicate Pairs: {summary_stats['duplicate_pairs']}\n",
    "Thin Pages: {summary_stats['thin_pages']}\n",
    "Similarity Threshold: {summary_stats['similarity_threshold']}\n",
    "Thin Threshold: {summary_stats['thin_threshold']} words\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center')\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title('Summary Statistics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This enhanced analysis includes:\n",
    "- **Sentiment Analysis**: VADER-based sentiment scoring\n",
    "- **Named Entity Recognition**: Extraction and categorization of entities\n",
    "- **Topic Modeling**: LDA-based topic discovery\n",
    "- **Advanced Keywords**: TF-IDF with n-grams\n",
    "- **Comprehensive Visualizations**: Heatmaps, word clouds, distributions\n",
    "\n",
    "All results demonstrate the power of NLP for SEO content analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
